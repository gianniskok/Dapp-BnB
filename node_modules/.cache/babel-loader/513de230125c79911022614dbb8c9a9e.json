{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n  apply(compiler) {\n    compiler.hooks.compilation.tap(\"MergeDuplicateChunksPlugin\", compilation => {\n      compilation.hooks.optimizeChunksBasic.tap(\"MergeDuplicateChunksPlugin\", chunks => {\n        // remember already tested chunks for performance\n        const notDuplicates = new Set(); // for each chunk\n\n        for (const chunk of chunks) {\n          // track a Set of all chunk that could be duplicates\n          let possibleDuplicates;\n\n          for (const module of chunk.modulesIterable) {\n            if (possibleDuplicates === undefined) {\n              // when possibleDuplicates is not yet set,\n              // create a new Set from chunks of the current module\n              // including only chunks with the same number of modules\n              for (const dup of module.chunksIterable) {\n                if (dup !== chunk && chunk.getNumberOfModules() === dup.getNumberOfModules() && !notDuplicates.has(dup)) {\n                  // delay allocating the new Set until here, reduce memory pressure\n                  if (possibleDuplicates === undefined) {\n                    possibleDuplicates = new Set();\n                  }\n\n                  possibleDuplicates.add(dup);\n                }\n              } // when no chunk is possible we can break here\n\n\n              if (possibleDuplicates === undefined) break;\n            } else {\n              // validate existing possible duplicates\n              for (const dup of possibleDuplicates) {\n                // remove possible duplicate when module is not contained\n                if (!dup.containsModule(module)) {\n                  possibleDuplicates.delete(dup);\n                }\n              } // when all chunks has been removed we can break here\n\n\n              if (possibleDuplicates.size === 0) break;\n            }\n          } // when we found duplicates\n\n\n          if (possibleDuplicates !== undefined && possibleDuplicates.size > 0) {\n            for (const otherChunk of possibleDuplicates) {\n              if (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue; // merge them\n\n              if (chunk.integrate(otherChunk, \"duplicate\")) {\n                chunks.splice(chunks.indexOf(otherChunk), 1);\n              }\n            }\n          } // don't check already processed chunks twice\n\n\n          notDuplicates.add(chunk);\n        }\n      });\n    });\n  }\n\n}\n\nmodule.exports = MergeDuplicateChunksPlugin;","map":{"version":3,"names":["MergeDuplicateChunksPlugin","apply","compiler","hooks","compilation","tap","optimizeChunksBasic","chunks","notDuplicates","Set","chunk","possibleDuplicates","module","modulesIterable","undefined","dup","chunksIterable","getNumberOfModules","has","add","containsModule","delete","size","otherChunk","hasRuntime","integrate","splice","indexOf","exports"],"sources":["/Users/iaonniskokkoros/Documents/OG BrokeBoiz/node_modules/webpack/lib/optimize/MergeDuplicateChunksPlugin.js"],"sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n\tapply(compiler) {\n\t\tcompiler.hooks.compilation.tap(\n\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\tcompilation => {\n\t\t\t\tcompilation.hooks.optimizeChunksBasic.tap(\n\t\t\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\t\t\tchunks => {\n\t\t\t\t\t\t// remember already tested chunks for performance\n\t\t\t\t\t\tconst notDuplicates = new Set();\n\n\t\t\t\t\t\t// for each chunk\n\t\t\t\t\t\tfor (const chunk of chunks) {\n\t\t\t\t\t\t\t// track a Set of all chunk that could be duplicates\n\t\t\t\t\t\t\tlet possibleDuplicates;\n\t\t\t\t\t\t\tfor (const module of chunk.modulesIterable) {\n\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t// when possibleDuplicates is not yet set,\n\t\t\t\t\t\t\t\t\t// create a new Set from chunks of the current module\n\t\t\t\t\t\t\t\t\t// including only chunks with the same number of modules\n\t\t\t\t\t\t\t\t\tfor (const dup of module.chunksIterable) {\n\t\t\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t\t\tdup !== chunk &&\n\t\t\t\t\t\t\t\t\t\t\tchunk.getNumberOfModules() === dup.getNumberOfModules() &&\n\t\t\t\t\t\t\t\t\t\t\t!notDuplicates.has(dup)\n\t\t\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t\t\t// delay allocating the new Set until here, reduce memory pressure\n\t\t\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates = new Set();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.add(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when no chunk is possible we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) break;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t// validate existing possible duplicates\n\t\t\t\t\t\t\t\t\tfor (const dup of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\t\t// remove possible duplicate when module is not contained\n\t\t\t\t\t\t\t\t\t\tif (!dup.containsModule(module)) {\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.delete(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when all chunks has been removed we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates.size === 0) break;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// when we found duplicates\n\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\tpossibleDuplicates !== undefined &&\n\t\t\t\t\t\t\t\tpossibleDuplicates.size > 0\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tfor (const otherChunk of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\tif (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n\t\t\t\t\t\t\t\t\t// merge them\n\t\t\t\t\t\t\t\t\tif (chunk.integrate(otherChunk, \"duplicate\")) {\n\t\t\t\t\t\t\t\t\t\tchunks.splice(chunks.indexOf(otherChunk), 1);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// don't check already processed chunks twice\n\t\t\t\t\t\t\tnotDuplicates.add(chunk);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n}\nmodule.exports = MergeDuplicateChunksPlugin;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;;AAEA,MAAMA,0BAAN,CAAiC;EAChCC,KAAK,CAACC,QAAD,EAAW;IACfA,QAAQ,CAACC,KAAT,CAAeC,WAAf,CAA2BC,GAA3B,CACC,4BADD,EAECD,WAAW,IAAI;MACdA,WAAW,CAACD,KAAZ,CAAkBG,mBAAlB,CAAsCD,GAAtC,CACC,4BADD,EAECE,MAAM,IAAI;QACT;QACA,MAAMC,aAAa,GAAG,IAAIC,GAAJ,EAAtB,CAFS,CAIT;;QACA,KAAK,MAAMC,KAAX,IAAoBH,MAApB,EAA4B;UAC3B;UACA,IAAII,kBAAJ;;UACA,KAAK,MAAMC,MAAX,IAAqBF,KAAK,CAACG,eAA3B,EAA4C;YAC3C,IAAIF,kBAAkB,KAAKG,SAA3B,EAAsC;cACrC;cACA;cACA;cACA,KAAK,MAAMC,GAAX,IAAkBH,MAAM,CAACI,cAAzB,EAAyC;gBACxC,IACCD,GAAG,KAAKL,KAAR,IACAA,KAAK,CAACO,kBAAN,OAA+BF,GAAG,CAACE,kBAAJ,EAD/B,IAEA,CAACT,aAAa,CAACU,GAAd,CAAkBH,GAAlB,CAHF,EAIE;kBACD;kBACA,IAAIJ,kBAAkB,KAAKG,SAA3B,EAAsC;oBACrCH,kBAAkB,GAAG,IAAIF,GAAJ,EAArB;kBACA;;kBACDE,kBAAkB,CAACQ,GAAnB,CAAuBJ,GAAvB;gBACA;cACD,CAhBoC,CAiBrC;;;cACA,IAAIJ,kBAAkB,KAAKG,SAA3B,EAAsC;YACtC,CAnBD,MAmBO;cACN;cACA,KAAK,MAAMC,GAAX,IAAkBJ,kBAAlB,EAAsC;gBACrC;gBACA,IAAI,CAACI,GAAG,CAACK,cAAJ,CAAmBR,MAAnB,CAAL,EAAiC;kBAChCD,kBAAkB,CAACU,MAAnB,CAA0BN,GAA1B;gBACA;cACD,CAPK,CAQN;;;cACA,IAAIJ,kBAAkB,CAACW,IAAnB,KAA4B,CAAhC,EAAmC;YACnC;UACD,CAlC0B,CAoC3B;;;UACA,IACCX,kBAAkB,KAAKG,SAAvB,IACAH,kBAAkB,CAACW,IAAnB,GAA0B,CAF3B,EAGE;YACD,KAAK,MAAMC,UAAX,IAAyBZ,kBAAzB,EAA6C;cAC5C,IAAIY,UAAU,CAACC,UAAX,OAA4Bd,KAAK,CAACc,UAAN,EAAhC,EAAoD,SADR,CAE5C;;cACA,IAAId,KAAK,CAACe,SAAN,CAAgBF,UAAhB,EAA4B,WAA5B,CAAJ,EAA8C;gBAC7ChB,MAAM,CAACmB,MAAP,CAAcnB,MAAM,CAACoB,OAAP,CAAeJ,UAAf,CAAd,EAA0C,CAA1C;cACA;YACD;UACD,CAhD0B,CAkD3B;;;UACAf,aAAa,CAACW,GAAd,CAAkBT,KAAlB;QACA;MACD,CA5DF;IA8DA,CAjEF;EAmEA;;AArE+B;;AAuEjCE,MAAM,CAACgB,OAAP,GAAiB5B,0BAAjB"},"metadata":{},"sourceType":"script"}